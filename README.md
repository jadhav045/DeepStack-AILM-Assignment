
# LLM-Based User Input Validator

A strict, LLM-powered validation script that enforces data integrity without using traditional regex or validation libraries. Built with Python, this tool relies entirely on Large Language Models to interpret and validate user profiles against complex international standards (ISO-3166, E.164).

It is designed to be **provider-agnostic**, supporting OpenAI, Groq, and other OpenAI-compatible APIs.

## ğŸš€ Features

* **Pure LLM Validation:** Logic is driven by Few-Shot Prompting to enforce rules like "valid ISO-2 country code" and "E.164 phone format" without hardcoded string manipulation.
* **Strict JSON Output:** Utilizes `response_format={"type": "json_object"}` to guarantee deterministic, machine-readable validation results.
* **Automated Evaluations:** Includes a comprehensive `promptfoo` test suite to verify schema compliance, error detection, and warning logic across edge cases.
* **Interactive Web Dashboard:** Includes a **Streamlit** UI for real-time, visual testing of the validator.
* **Provider-Agnostic:** Seamlessly switch between paid models (OpenAI GPT-4o) and free/open-source models (Groq Llama-3) via environment variables.

## ğŸ› ï¸ Setup Instructions

### Prerequisites

* **Python 3.10+** (Required for type hinting and library support)
* **Node.js** (Required to run the `promptfoo` evaluation suite)

### Installation

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/yourusername/llm-validator.git](https://github.com/yourusername/llm-validator.git)
    cd llm-validator
    ```

2.  **Create and activate a virtual environment:**
    ```bash
    # Create venv
    python -m venv venv

    # Activate (Windows)
    venv\Scripts\activate

    # Activate (Mac/Linux)
    source venv/bin/activate
    ```

3.  **Install Python dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

## âš™ï¸ Configuration

The project uses a `.env` file to manage API keys and model selection.

1.  **Initialize Environment Variables:**
    ```bash
    cp .env.example .env
    # Or manually create a .env file
    ```

2.  **Configure your preferred LLM provider:**

    ### Option A: OpenAI (Paid)
    ```ini
    LLM_API_KEY=sk-proj-your-openai-key
    LLM_BASE_URL=[https://api.openai.com/v1](https://api.openai.com/v1)
    LLM_MODEL=gpt-4o-mini
    ```

    ### Option B: Groq (Free Tier / High Speed)
    ```ini
    LLM_API_KEY=gsk_your-groq-key
    LLM_BASE_URL=[https://api.groq.com/openai/v1](https://api.groq.com/openai/v1)
    LLM_MODEL=llama3-70b-8192
    ```

## ğŸƒ How to Run

### 1. Command Line Interface (CLI)
The script accepts a single JSON file as an argument and outputs the validation result in strict JSON format.

**Command:**
```bash
python validate_user.py <path_to_input_file.json>

```

**Example Usage:**

```bash
# Run with included test data
python validate_user.py data/valid_user.json

```

### 2. Interactive Web Dashboard ğŸŒŸ

Launch the Streamlit dashboard to test the validator via a graphical interface. This allows you to fill out a form and see the AI validation logic in real-time.

**Command:**

```bash
streamlit run app.py

```

*This will automatically open a new tab in your default web browser.*

## ğŸ§ª How to Run Evaluations

This project uses **Promptfoo** to ensure the LLM behaves correctly across edge cases and correctly distinguishes between "Errors" (invalid data) and "Warnings" (risky data).

1. **Initialize Promptfoo** (One-time setup if not installed globally):
```bash
npx promptfoo@latest init

```


2. **Run the Test Suite:**
Execute the evaluation using the provided configuration file (located in the `tests/` folder):
```bash
npx promptfoo eval -c tests/promptfoo.yaml

```



### What is Tested?

The test suite covers the following scenarios:

* âœ… **Happy Path:** Valid inputs with correct formatting.
* âŒ **Critical Errors:**
* Phone number not in E.164 format.
* Country code not complying with ISO-3166-1 alpha-2.
* Missing required fields (Name, Email).


* âš ï¸ **Warnings:**
* Phone country code does not match the `country` field.
* Use of disposable email domains (e.g., tempmail).
* User age under 18.



## ğŸ“‚ Project Structure

```text
.
â”œâ”€â”€ data/               # ğŸ“‚ JSON test files (input.json, valid_user.json, etc.)
â”œâ”€â”€ tests/              # ğŸ§ª Automated evaluation suite
â”‚   â”œâ”€â”€ promptfoo.yaml  #    - Eval configuration
â”‚   â””â”€â”€ test_wrapper.py #    - Python bridge for Promptfoo
â”œâ”€â”€ validate_user.py    # ğŸš€ Main CLI application logic
â”œâ”€â”€ app.py              # ğŸŒ Streamlit Web Dashboard
â”œâ”€â”€ requirements.txt    # ğŸ“¦ Python dependencies
â”œâ”€â”€ .env                # ğŸ”’ API credentials (excluded from Git)
â””â”€â”€ README.md           # ğŸ“– Project documentation

```

## ğŸ§  Design Philosophy

1. **No Hardcoded Logic:** The script contains zero regex or `if/else` checks for data format. All validation logic is inferred by the LLM based on high-level instructions (e.g., "Validate against ISO-2").
2. **Schema Enforcement:** We use `response_format={"type": "json_object"}` to prevent the LLM from generating conversational filler, ensuring the output is always parseable by downstream systems.
3. **Separation of Concerns:**
* **Errors** are reserved for syntactically invalid or missing data.
* **Warnings** are reserved for valid but semantically risky data (e.g., disposable emails).



## ğŸ“„ License

This project is licensed under the MIT License.

```
